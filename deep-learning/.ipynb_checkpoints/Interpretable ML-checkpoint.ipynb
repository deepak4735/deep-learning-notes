{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretable ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Building Blocks of Interpretability\n",
    "\n",
    "https://distill.pub/2018/building-blocks/\n",
    "\n",
    " build deep abstractions and instantiate these abstractions in rich interfaces. \n",
    "\n",
    "### Feature Visualization\n",
    "\n",
    "**Articles**\n",
    "1. Visualizing higher-layer features of a deep network\n",
    "    D. Erhan, Y. Bengio, A. Courville, P. Vincent.\n",
    "    University of Montreal, Vol 1341, pp. 3. 2009.\n",
    "\n",
    "2. Feature Visualization  \n",
    "    C. Olah, A. Mordvintsev, L. Schubert.\n",
    "    Distill. 2017. \n",
    "    DOI: 10.23915/distill.00007\n",
    "\n",
    "3. Deep inside convolutional networks: Visualising image classification models and saliency maps \n",
    "    K. Simonyan, A. Vedaldi, A. Zisserman.\n",
    "    arXiv preprint arXiv:1312.6034. 2013.\n",
    " 4.Deep neural networks are easily fooled: High confidence predictions for unrecognizable images  \n",
    "    A. Nguyen, J. Yosinski, J. Clune.\n",
    "    Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 427--436. 2015. \n",
    "    DOI: 10.1109/cvpr.2015.7298640\n",
    "5. Inceptionism: Going deeper into neural networks \n",
    "    A. Mordvintsev, C. Olah, M. Tyka.\n",
    "    Google Research Blog. 2015.\n",
    "6. Plug & play generative networks: Conditional iterative generation of images in latent space. A. Nguyen, J. Clune, Y. Bengio, A. Dosovitskiy, J. Yosinski.\n",
    "    \n",
    "    \n",
    "### Attribution\n",
    "A set of techniques that answer such questions by explaining the relationships between neurons. There are a wide variety of approaches and more links on the original articles. \n",
    "\n",
    "1. Deep inside convolutional networks: Visualising image classification models and saliency maps \n",
    "K. Simonyan, A. Vedaldi, A. Zisserman.\n",
    "arXiv preprint arXiv:1312.6034. 2013.\n",
    "\n",
    "2. Visualizing and understanding convolutional networks \n",
    "M.D. Zeiler, R. Fergus.\n",
    "European conference on computer vision, pp. 818--833. 2014.\n",
    "Striving for simplicity: The all convolutional net \n",
    "J.T. Springenberg, A. Dosovitskiy, T. Brox, M. Riedmiller.\n",
    "arXiv preprint arXiv:1412.6806. 2014.\n",
    "\n",
    "3. Grad-cam: Why did you say that? visual explanations from deep networks via gradient-based localization \n",
    "R.R. Selvaraju, A. Das, R. Vedantam, M. Cogswell, D. Parikh, D. Batra.\n",
    "arXiv preprint arXiv:1610.02391. 2016.\n",
    "\n",
    "4. Interpretable Explanations of Black Boxes by Meaningful Perturbation \n",
    "R. Fong, A. Vedaldi.\n",
    "arXiv preprint arXiv:1704.03296. 2017.\n",
    "\n",
    "5. PatternNet and PatternLRP--Improving the interpretability of neural networks \n",
    "P. Kindermans, K.T. Schutt, M. Alber, K. Muller, S. Dahne.\n",
    "arXiv preprint arXiv:1705.05598. 2017. \n",
    "DOI: 10.1007/978-3-319-10590-1_53\n",
    "\n",
    "6. The (Un)reliability of saliency methods \n",
    "P. Kindermans, S. Hooker, J. Adebayo, M. Alber, K.T. Schutt, S. Dahne, D. Erhan, B. Kim.\n",
    "arXiv preprint arXiv:1711.00867. 2017.\n",
    "Axiomatic attribution for deep networks \n",
    "M. Sundararajan, A. Taly, Q. Yan.\n",
    "\n",
    "### Dimensionality Reduction\n",
    "\n",
    "\n",
    "### Work from the HCI community \n",
    "\n",
    "1. LSTMVis: A tool for visual analysis of hidden state dynamics in recurrent neural networks  [PDF]\n",
    "H. Strobelt, S. Gehrmann, H. Pfister, A.M. Rush.\n",
    "IEEE Transactions on Visualization and Computer Graphics, Vol 24(1), pp. 667--676. IEEE. 2018. \n",
    "DOI: 10.1109/tvcg.2017.2744158\n",
    "2. ActiVis: Visual Exploration of Industry-Scale Deep Neural Network Models  [PDF]\n",
    "M. Kahng, P.Y. Andrews, A. Kalro, D.H.P. Chau.\n",
    "IEEE Transactions on Visualization and Computer Graphics, Vol 24(1), pp. 88--97. IEEE. 2018. \n",
    "DOI: 10.1109/tvcg.2017.2744718\n",
    "3. Do convolutional neural networks learn class hierarchy?  [PDF]\n",
    "A. Bilal, A. Jourabloo, M. Ye, X. Liu, L. Ren.\n",
    "IEEE Transactions on Visualization and Computer Graphics, Vol 24(1), pp. 152--162. IEEE. 2018. \n",
    "\n",
    "Current inadequete approaches: \n",
    " saliency maps or correlating abstract neurons\n",
    " \n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
