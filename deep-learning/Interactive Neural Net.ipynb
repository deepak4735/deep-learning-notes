{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Neural Net\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvNetJS\n",
    "\n",
    "## RL Demo\n",
    "1. Provides description of the arena and what everything is as well as the code- in the site so that you can see how the API looks.\n",
    "2. There are state visualizations: \n",
    "    1. Value appoximation function neural network: an unknown scheme shows the layers of the network with acitvations\n",
    "    2. Input bar graph: Not sure what's going on- it says collected input state. \n",
    "    3. Average reward over time. \n",
    "    4. Provides raw data for experirence replay size, exploration epsilon, age, average Q learning loss, and smooth-ish reward\n",
    "3. Provides the weights for a pre-trained network in the interface. \n",
    "4. Provides some controls: go very fast, go fast, go normal speed, go slow, start learning, stop learning. \n",
    "\n",
    "#### Improvements\n",
    "\n",
    "I want interaction with the environment by the user so we can see how perturbation changes the agent- maybe even comparison of different agents- or comparison of states. One of the issues with NN visualiation is that there is a lot of information that doesn't necessarily mean much- finidng ways of snapshotting the state and comparing against other states in time would be nice- imaine if you could dynamically load different weights so you could switch between network configurations.\n",
    "\n",
    "The other thing to make salient is how the agent is making decisions or how it's decisions change over time, how it choses to interact with the environment- one way might be a visualization of the final layer, potentially one that maps to the arena. visualizing the weights without some way of aggregated them or showing what they stand for isn't very useful. \n",
    "\n",
    "A more mathematical description of what's going on. Some of this can be in the description. I think I'll write out an explicit version of the the agent's math and just share it with people and see what they would need to understand what's going on or **what questions they ask.** \n",
    "\n",
    "The most useful parts are the reward function and loading different weights.\n",
    "\n",
    "I'm not sure what I'd do to make better controls or more meanigful use of the layer visualization. Giving people greater power to break the model might help- a combination of interacting with the arena or changing weights be hand- I think the changing weights by hand or **something that tracks changes in weight updates** so that you can observe weights that change together-\n",
    "\n",
    "The last piece is to switch between different RL strategies. \n",
    "\n",
    "## MNIST Demo\n",
    "\n",
    "I really like this demo as a way of looking at the weights. Karpathy hits it out the park- implements a lot of what I wanted out of the RL demo, and gives what I think is the most meaningful visualization of the weights. \n",
    "\n",
    "Even just a slight reimplementation of this could be amazing. It could use some better wording or and a better layout but the 'activation gradients' are so meaninfgul and give a goode idea of what is being turned on by the network. This with a GAN could be incredible. \n",
    "\n",
    "## CIFAR-10 \n",
    "\n",
    "Just like the MNIST, really great and worth coming back to. I think what I'd most want is a GAN version and something that lets me understand one-pixel attacks. It could be interesting to look at the papers and blogs about advesarial attacks and set up something that lets people try to hunt for pixels that change the network. \n",
    "\n",
    "## 2D Classification with 2-layer network\n",
    "\n",
    "Great, not much else to say. All I could want is more- more ability to dynamically load data and change the network. \n",
    "\n",
    "## Denoising Autoencoder MNIST\n",
    "\n",
    "Continues the pattern he started with the MNIST dataset. \n",
    "\n",
    "Overall this is an incredibl project and I think in extending it with deeplearn.js **one of the most helpful things for myself and others is a small biolerplate that exposes a coding environment to upload weight json and see the code for the network.** In time I could add more so that you can visualize or otherwise access parts of the network.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep RL Bootcamp\n",
    "\n",
    "### Notes on demos\n",
    "1. Having a line graph of value versus policy function to see where they converge and how they are look throught the training- rl seems to lend itself to more meaningful visualization because there are calculated values that are informed by the neural net rather than just a neural net and its weights\n",
    "2. In Rocky Duan's video he has the state spaces of the q-learning bot. It allows you to see the action the bot has chosen which meanders during the exploration space and during the policy phase you can see that the robot walks (the goal of the bot) by choosing the same sequence of four state spaces. Really great demo at showing that action.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
