{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highlights from Part 1\n",
    "\n",
    "1. Universal computabililty theorem -Stacks of non-linear functions can approximate any continuous function. \n",
    "2. Dense layers are slow and most modeern nets do not use them\n",
    "3. CNNs for fixed-size ordered data. \n",
    "4. Softmax for categories\n",
    "5. Relu for inner activations \n",
    "\n",
    "### Five steps to avoid overfitting\n",
    "1. More data\n",
    "2. Data augmentation\n",
    "3. Generalizable architectures\n",
    "4. Regularization\n",
    "5. Reduce architexture complexity\n",
    "\n",
    "6. The general approach - with a new problem. Start with a network that is too big, that is not regularized, and try to overfit terribly- if it can't do that then throw out the network before regularization. First try to overfit the training data and then use the above steps to create the network. \n",
    "7. Embeddings allow us to use categorical data like words or labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Episode 8 \n",
    "\n",
    "1. More ram in your gpu setup helps more than people give it credit, more ram means bigger batch sizes, smoother graidents, qucker epochs. \n",
    "\n",
    "### Style Transfer\n",
    "1. Loss function of style transfer- something really interesting with style transfer is the loss function - which in this case is the 'later layers of a vgg like neural network' that is being used to identify if the current image looks like what it is supposed to look like. Something else about this model is that it does not use max pooling because max pooling loses information about its original input size, average pooling is used instead because it will not. In generative models it is very hard to get back to data that you loose in max pooling. Average ppoling is a little better because it holds onto some of the context of the image data. \n",
    "\n",
    "2. Scipy.optimize has many functions like momentum \n",
    "\n",
    "### F Style\n",
    "1. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
